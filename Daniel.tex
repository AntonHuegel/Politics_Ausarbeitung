% Teil Daniel

\definecolor{rahmen}{rgb}{1,.7,.7}

\section{Big Data und Social Bots}
Mit der rasch fortschreitenden Verbreitung des Internets im Alltag der Gesellschaft stellen wir heute fest, dass Soziale Medien eine wichtige Informationsquelle für Teile der Bevölkerung darstellen. Die Daten der einzelnen Informationsdienstleister sind dort gebündelt und können von den publizierenden Personen ohne Umwege an den Leser bereitgestellt werden. Im politischen Kontext sind weite Teile von Politikern, Parteien und Einrichtungen in den sozialen Medien präsent. Diese können dem Wähler dort zusätzlich simplifizierte Inhalte bereitstellen, die ohne Umwege und unkommentiert zur Verfügung stehen. In den USA stellt das soziale Netzwerk Twitter sogar eine Hauptinformationsquelle des Präsidenten dar.
\newline
Doch die direkte Kommunikation mit dem Nutzer stellt diesen auch vor ganz neue Herausforderungen. Seit einiger Zeit tauchen im Internet häufig sogenannte Fake News auf. Darunter versteht man Nachrichten, die nach außen hin erstmal seriös wirken, sich bei genauerer Recherche jedoch als falsch erweisen. Da der durchschnittliche Nutzer selten die Quellen von Berichten überprüft, stellt dies ein zunehmendes Problem dar. Eng damit verknüpft ist der Einsatz von Social Bots. Unter einem Social Bot versteht man ein Programm, welches automatisiert Tätigkeiten in sozialen Netzwerken ausführt, beispielsweise das Upvoten oder Erstellen von Beiträgen. Durch die Ranking-Algorithmen, die die Prioritäten von Beiträgen bewerten, kann so die Anzeige von Beiträgen manipuliert werden. Das Erkennen von Bots funktioniert teilweise sehr einfach, da nur vorgefertigte Texte verwendet werden. Einige Programme sind jedoch komplexer geschrieben und von realen Nutzern nur schwer unterscheidbar.
\newline
Mit der Initiative der Bundesregierung gegen Hasskommentare im Netz stehen die Betreiber der Netzwerke nun vor einer großen Herausforderung: Millionen Beiträge müssen auf illegale oder unpassende Inhalte überprüft werden. Die große Anzahl an Postings verhindert dabei nahezu den Einsatz menschlicher Moderatoren, es braucht eine automatische Überprüfung. Ein Ansatz zur automatischen Analyse von Texten liefert dieses Paper. Anhang des vorgestellten Modells soll es möglich sein, Texte zu Verstehen und diese in gewisse Dimensionen einzuordnen. Anhand dieser Einordnung kann so die inhaltliche Position des Textes bzw. des Autors ermittelt werden. Im den nachfolgenden Kapiteln werden die einzelnen Schritte zur Analyse und Einordnung des Textes geschildert und anschließend anhand von einigen politischen Texten vorgenommen.

\section{Akquirierung von Texten}
Um politische Texte analysieren zu können müssen zuallererst passende Texte beschafft werden. Quellen für solche Texte sind verschiedene vorhanden, welche mehr oder weniger gut geeignet sind, um automatisch analysiert zu werden. Im Folgenden werden drei Kategorien kurz vorgestellt.

\subsection{Textbasiert}
Rein auf den gedruckten Text ausgelegte Medien, wie beispielsweise Zeitungen oder Magazine, sind für den Computer im Allgemeinen schwer auszuwerten. Die Daten müssten manuell eingescannt werden und anschließend per Bildbearbeitungsprogramm in ein geeignetes Zeichenformat übersetzt werden. 

\subsection{Audio/Video}
Medien, welche Nachrichten per Audio oder Video übertragen, sind ebenfalls relativ uninteressant für die automatische Analyse. Hierzu zählen beispielsweise Fernsehsendungen, Radiosender oder auch Podcasts im Internet. Ähnlich wie bei den rein gedruckten Medien besteht auch hier das Problem, die Textinformationen in ein für den Computer „leserliches“ Format zu konvertieren. Insbesondere bei akustischen Signalen, also gesprochenem Text, ist diese Analyse sehr aufwändig und Fehleranfällig. 

\subsection{Internet}
Das Internet gilt als die Beste Bezugsquelle für maschinell auswertbare Texte. Jedoch sind auch hier Einschränkungen vorhanden, da die Texte ebenfalls für den menschlichen Leser optimiert sind. Im Internet kann man einige Bezugsquellen unterscheiden:
\begin{itemize}
\item Webseiten einzelner Anbieter
\item Soziale Medien
\item Per API zur Verfügung gestellte Daten
\end{itemize}
Es ist eine große Herausforderung, Texte von Webseiten automatisiert analysieren zu lassen. Die Schwierigkeit hierbei ergibt sich aus der Tatsache, dass die HTML-Struktur der einzelnen Seiten gravierende Unterschiede aufweisen kann. Die \textit{Hypertext Markup Language (HTML)} ist speziell dafür designed, statische Inhalte in vielfacher Art und Weise darzustellen. Dies setzt eine hohe Interpretationsfähigkeit des verarbeitenden Programmes voraus.
\newline
Soziale Medien wie Facebook oder Twitter hingegen stellen selbst häufig eine sogenannte \textit{Application Programming Interface (API)} zur Verfügung, mit deren Hilfe automatisch Inhalte abgefragt werden können. Die Abfrage hierbei erfolgt direkt mittels \textit{HTTP (Hypertext Transfer Protocol) GET-Abfrage}, welcher auch manuell ausgeführt werden kann und ausreichend Platz für Parameter zur Verfügung stellt. Bei erfolgreicher Anfrage erhält man als Antwort eine Zeichenkette, welche zumeist in \textit{XML (Extensible Markup Language)} oder im moderneren \textit{JSON (JavaScript Object Notation)} vorliegen. Alle bekannteren Programmier- und Skriptsprachen bringen bereits Parser für beide Formate mit, sodass die Daten direkt in das Programm eingelesen werden können.

\section{Datenbanken}
Das nachfolgente Teilkapitel orientiert sich inhaltlich an \cite{datenbanken}.
Im Zuge der Textverarbeitung trifft man immer wieder auf den Begriff der Datenbanken. Diese sind im ein wichtiges Werkzeug, um die Textmanipulation sinnvoll zu unterstützen. Eine Datenbank stellt die nötigen Funktionen zur Verfügung, um große Datenmengen effizient zu speichern, zu analysieren und zu verarbeiten. Im Bereich der relationalen Datenbanken ist die Sprache SQL (Structured Query Language) weitgehend verbreitet. Diese bietet unterschiedliche Möglichkeiten an, die gespeicherten Daten abzufragen und zu manipulieren:
\begin{itemize}
\item INSERT
\item UPDATE
\item SELECT
\item SORT
\item JOIN
\item DELETE
\end{itemize}
Logische Bedingungen können, wie in anderen Sprachen auch, mit in die Abfragen integriert werden. Diese werden durch einige zusätzliche Funktionen unterstützt. Beispielsweise lassen sich die Länge von Texten oder Mittelwerte schnell berechnen und in die logische Bedingung integrieren.
Wichtig hierbei ist ebenfalls der Begriff der Normalisierung. Um Konsitenz zu wahren und Redundanzen zu vermeiden existieren verschiedene Normalformen:
\begin{itemize}
\item 1NF - Erste Normalform
\item 2NF - Zweite Normalform
\item 3NF - Dritte Normalform
\item BCNF - Boyce-Codd Normalform
\end{itemize}
Die Formen sind hierbei anhand ihrer Striktheit aufsteigend angeordnet. Als ein Beispiel aus dem Kontext der politischen Textanalyse wird ein kurzes Schema zur Speicherung politischer Texte vorgestellt. Relevante Informationen sind hierbei die Herkunft des Textes (Politiker, Partei) sowie eine eindeutige Zuordnung anhand einer Identifikationsnummer. \\
\begin{table}
\begin{tabular}{llllll}
\hline
ID & Partei & Kürzel & Vorname & Nachname & Text \\
\hline
1 & Christlich Demokratische Union & CDU & Angela & Merkel & Text1 \\
2 & Christlich Demokratische Union & CDU & Angela & Merkel & Text2 \\
3 & Christlich Demokratische Union & CDU & Angela & Merkel & Text3 \\
4 & Christlich Demokratische Union & CDU & Angela & Merkel & Text4 \\
5 & Sozialdemokratische Partei Deutschlands & SPD & Sigmar & Gabriel & Text5 \\
\hline
\end{tabular}
\caption{Beispieldaten mit Redundanzen}
\end{table}
Offensichtlich werden hier die Daten der Partei sowie der Politiker redundant gespeichert, was suboptimal ist. Um einer möglichst hohen Normalform zu entsprechen wird die Tabelle in drei Tabellen aufgespalten: Je eine Tabelle für die Parteien, die Politiker und die Texte: \newline
\begin{table}
\begin{tabular}{lll}
\hline
ID & Partei & Kürzel \\
\hline
1 & Christlich Demokratische Union & CDU \\
2 & Sozialdemokratische Partei Deutschlands & SPD \\
\hline
\end{tabular}
\newline \newline
\begin{tabular}{llll}
\hline
ID & Vorname & Nachname & Partei-ID\\
\hline
1 & Angela & Merkel & 1\\
2 & Sigmar & Gabriel & 2\\
\hline
\end{tabular}
\newline \newline
\begin{tabular}{lll}
\hline
ID & Politiker-ID & Text \\
\hline
1 & 1 & Text1 \\
2 & 1 & Text2 \\
3 & 1 & Text3 \\
4 & 1 & Text4 \\
5 & 2 & Text5 \\
\hline
\end{tabular}
\caption{Beispieltabellen in Normalform}
\end{table}
\\
Die Identifikationsnummer aller drei Tabellen kommt hierbei auch als Schlüssel ins Spiel. Über den Schlüssel bzw. Index können Einträge in einer Tabelle eindeutig identifiziert werden, was sehr effiziente Abfragen ermöglicht. Andererseits werden eben jene IDs in anderen Tabellen als sogenannte Fremdschlüssel verwendet: Sie zeigen auf Schlüssel anderer Tabellen, um Redundanzen zu vermeiden. In obigem Beispiel sind die \textit{Partei-ID} und die \textit{Politiker-ID} Fremdschlüssel. Im Hinblick auf Fremdschlüssel ist besonders auf die Konsistenz der Datensätze zu achten. Wäre beispielsweise der Politiker \textit{Sigmar Gabriel} nicht vorhanden, also die \textit{Politiker-ID} 2 nicht vergeben, so würden die anderen Tabellen auf ungültige Datensätze verweisen.

\section{Textvorverarbeitung}
Das Kapitel der Textverarbeitung setzt sich aus den den folgenden Quellen zusammen: \cite{deutschinfo}, \cite{openthesaurus}, \cite{morphy}, \cite{wikipedia}, \cite{webmining} und \cite{zeichenkodierung}.
Da die Texte, so wie sie im Internet zur Verfügung gestellt werden, für das Lesen durch den Menschen optimiert sind, müssen noch einige zusätzliche Schritte ausgeführt werden, damit die Daten auch effektiv durch den Computer ausgewertet werden können. Anhand von dem folgenden Beispieltext wird die Notwendigkeit für eine solche Vorverarbeitung deutlich. Die Schritt, die hierbei zur Aufbereitung des Textes durchgeführt werden, werden später in der Ausarbeitung detailliert beschrieben. Der Text ist ein Beitrag von Christian Lindner über Facebook.
\newline
\begin{quote}
\colorbox{rahmen}{"Wir} wollen scheinbare \colorbox{rahmen}{Gegensätze} verbinden\colorbox{rahmen}{. Umweltschutz} muss nicht wie bei \colorbox{rahmen}{Rot-Grün} die \colorbox{rahmen}{Wirtschaft} fesseln\colorbox{rahmen}{. Man} kann die \colorbox{rahmen}{Sicherheit stärken}, ohne \colorbox{rahmen}{Bürgerrechte einzuschränken. Soziale Verantwortung übernimmt} man besser mit \colorbox{rahmen}{Bildung} als mit \colorbox{rahmen}{Umverteilung.}"
\end{quote}

Wie zu sehen ist sind im Text noch diverse Sonderzeichen inklusive Umlaute vorhanden. Diese wurden farblich markiert. Ebenfalls für die Semantik nicht unmittelbar wichtig ist die Groß- und Kleinschreibung der Worte.
\newline

\begin{quote}
\colorbox{rahmen}{wir} wollen scheinbare \colorbox{rahmen}{gegensaetze} verbinden umweltschutz muss nicht wie bei rot gruen \colorbox{rahmen}{die} wirtschaft fesseln man \colorbox{rahmen}{kann die} sicherheit staerken ohne buergerrechte einzuschraenken soziale verantwortung \colorbox{rahmen}{uebernimmt} man \colorbox{rahmen}{besser} mit bildung als mit umverteilung
\end{quote}

Im nächsten Schritt werden die Wörter auf ihren bekannten Wortstamm reduziert um Mehrfachzählung identischer Worte zu verhindern, die lediglich in einer anderen Form vorliegen. 
\newline
\begin{quote}
\colorbox{rahmen}{ich} wollen scheinbare gegensatz verbinden umweltschutz muss nicht \colorbox{rahmen}{wie} bei rot gruen \colorbox{rahmen}{der} wirtschaft fesseln \colorbox{rahmen}{man} koennen \colorbox{rahmen}{der} sicherheit staerken \colorbox{rahmen}{ohne} buergerrechte einschraenken soziale verantwortung uebernehmen \colorbox{rahmen}{man} gut \colorbox{rahmen}{mit} bildung \colorbox{rahmen}{als mit} umverteilung
\end{quote}

Im letzten Schritt werden für den Textinhalt irrelevante Wörter herausgefilert, beispielsweise Artikel und Pronomen.
\newline
\begin{quote}
wollen scheinbare gegensatz verbinden umweltschutz muss nicht rot gruen wirtschaft fesseln koennen sicherheit staerken buergerrechte einschraenken soziale verantwortung uebernehmen gut bildung umverteilung
\end{quote}

Wie man sieht ist der Text in dieser Form für den Menschen nur noch bedingt lesbar. Zwar sind noch alle wichtigen Begriffe vorhanden, die meisten grammatikalischen Notwendigkeiten sind jedoch verloren gegangen.

\subsection{Zeichenkodierung}
Die Zeichenkodierung ist ein Thema der Darstellung von Buchstaben und Zeichen im Bereich der IT. Grundsätzlich versteht ein Prozessor nur Datenreihen von binären Werten. Durch das Zusammenfassen dieser Werte zu Bytes können im Binärsystem unterschiedliche Zahlensysteme umgerechnet und dargestellt werden. Gerechnet wird überwiegend im Dezimalsystem, wobei auch das Hexadezimalsystem eine häufige Anwendung findet. In den meisten Programmier- bzw. Skriptsprachen entspricht die Länger einer Variablen ein Byte bis acht Byte, jenachdem ob Ganzzahlen oder Fließkommazahlen dargestellt werden und je nach Genauigkeit. Die Darstellung von Zeichen ist hierbei eigentlich ein Spezialfall, da für diese keine arithmetischen Operationen angedacht sind und diese somit besonders interpretiert werden können. Das Problem ist auch hier schnell identifiziert: Ein Zeichen mit der Länge 1 Byte kann 255 verschiedene Werte darstellen, ein Wert wird als Escape-Sequenz verwendet. Während 255 Zeichen für für die Anwendung im europäischen Raum ausreicht, ist dies für den asiatischen Raum zu wenig. Auf diese Weise haben sich verschiedene Kodierungen entwickelt, um möglichst vielen Anwendungsfällen zu genügen:
\begin{itemize}
\item{ASCII} Mit 128 Bit Länge können Zahlen, Buchstaben und Satzzeichen sowie einige weitere Sonderzeichen dargestellt werden. Durch den Unterschied Groß- und Kleinschreibung ist das Alphabet doppelt vorhanden. Die restlichen Bits sind ungenutzt.
\item{ISO-8859} Doppelt so lang wie ein ASCII-Zeichen können hier zusätzliche Sonderzeichen wie Umlaute gespeichert werden. Der ISO-Standard umfasst eine breite Palette an Versionen.
\item{Unicode} Das Unicode Transformation Format umfasst eine Reihe verschiedener Formate, deren Länge von 1 bis 4 Byte variieren kann. Aus dem Prinzip der Datensparsamkeit heraus wird meistens UTF-16 mit einer Länge von 2 Byte verwendet.
\end{itemize}
Da mit zunehmender Verbreitung des Internets und der damit einhergehenden weltweiten Vernetzung die Kommunikation nicht an unterschiedlichen Zeichensätzen scheitern soll, verwenden Webseiten und Programme größtenteils Unicode. 

\subsection{Reguläre Ausdrücke	}
Reguläre Ausdrücke werden in der Informationsverarbeitung bestimmte Muster aus Texten erkennen und extrahieren zu können. Das zu erkennende Muster wird hierbei ebenfalls als Zeichenkette mit spezieller Syntax übergeben. Hierbei werden über lateinische Zeichen, arabische Ziffern bis hin zu diversen Sonderzeichen die meisten Anwendungsfälle abgedeckt.
Eine sehr häufige Verwendung finden reguläre Ausdrücke im Bereich der Validierung von Nutzereingaben auf Webseiten, insbesondere in Formularen zur Datenübergabe. Einige bekannte Beispiele hierfür sind:
\newline
\begin{table}
\begin{tabular}{llll}
\hline
Name & Ausdruck & Beispiel \\
\hline
Postleitzahl & /[0-9]{5}/ & 87700 \\
Vorname/Nachname & /[a-zA-Z]+/ & Peter Lustig \\
E-Mail & /[a-zA-Z]+@[a-zA-Z]+.(de|com|net)/ & anonymous@uni-ulm.de \\
Telefonnummer & /[0-9]+[ -]{1,3}[0-9 ]{4,}/ & 0190 - 123 456 \\
\hline
\end{tabular}
\caption{Beispiele für Reguläre Ausdrücke und ihre Anwendung}
\end{table}

\subsection{Deutsche Grammatik	}
Im deutschen lassen sich Worte durch sogenannte Wortarten kategorisieren. Zu den Wortarten zählen: \\
\begin{table}
\center
\begin{tabular}{ll}
\hline
Wort & Beispiel \\
\hline
Nomen & Politiker, Partei \\
Artikel & der, die \\
Pronomen & dieser, dieses \\
Adjektive & rot, liberal \\
Verben & wählen, senken \\
Adverbien & schnell, laut \\
Konjunktionen & und, oder \\
Präpositionen & an, auf \\
\hline
\end{tabular}
\caption{Wortarten mit Beispielen}
\end{table}
Im allgemeinen können viele Sätze auf eine Grundform reduziert werden: Subjekt - Verb - Objekt. Anhand dieser Form ist es für ein Programm einfach,
einen Aussage aus einem Satz herauszuarbeiten. Da Sätze jedoch häufig verschachtelt und detaillierter ausformuliert sind, müssen diese weitestgehend vereinfacht
werden. Ein Schritt hierzu ist das Entfernen nicht-sinngebender Wortarten aus dem Text, also solcher Worte, die selbst keine essentielle Information beitragen 
sondern lediglich zur Wahrung der grammatikalischen Korrektheit im Text vorhanden sind. Die Wortarten im Text reduzieren sich damit auf Nomen, Adjektive, Verben
und Adverbien.
Ein zweiter Schritt ist das Reduzieren eben jener Wortformen auf ihre grammatikalische Grundform. Die Änderung ab von der Grundform nennt man bei Verben Konjugation
und bei Nomen Deklination. Die Variation der Wörter hängt hierbei von vielen verschiedenen Faktoren ab, beispielsweise der Zeitform oder der Person.

\subsection{Morphologie Datenbank}
Mit der Struktur von Wörtern setzt sich die sogenannte Morphologie auseinander. Wie im vorherigen Kapitel beschrieben können Wörter sowohl dekliniert als auch konjugiert werden. Nach einer solchen Veränderung ist das Wort zwar für den menschlichen Leser immer noch das gleiche, der Computer kann jedoch das konjugierte/deklinierte Wort nicht in einen Kontext mit dem Wortstamm bringen. Betrachtet man als Beispiel die folgenden zwei Sätze, so wird man feststellen, dass diese semantisch nahezu identisch sind:
\begin{itemize}
\item Peter ging gestern zur Schule.
\item Peter ist gestern zur Schule gegangen.
\end{itemize}
Für das weitere Textmodell sind jedoch beide Formen von \textit{gehen}, also \textit{ging} und \textit{ist gegangen}, trivial nicht zu unterscheiden.
\newline
Abhilfe für dieses Dilemma bietet die Morphologie Datenbank \textit{Morphy}, die im Internet verfügbar ist. Diese enthält circa eine Millionen deutsche Wörter mit ihren zugehörigen Stammformen. Damit bietet sie die Möglichkeit, alle im Text vorkommenden Wörter auf ihre Grundform zu reduzieren und so semantisch äquivalente Wörter in einen Konext zu bringen. 

\subsection{Synonym Datenbank}
Eine ähnliche Möglichkeit zur Bereinigung des Textes von semantisch identischen oder ähnlichen Wörtern bietet die Synonym-Datenbank \textit{OpenThesaurus}. Betrachtet man abermals das Beispiel von oben, so wird der Vorteil einer Synonym-Bereinigung schnell klar:
\begin{itemize}
\item Peter ist gestern zur Schule gegangen.
\item Peter ist gestern zur Schule gelaufen.
\end{itemize}
Entnimmt man dem Text als zentrale Information, dass Peter gestern in der Schule anwesend war, so ist die Information wie er dorthin gelangt ist unwichtig und kann ignoriert werden.
\newline
Hierfür stellt \textit{OpenThesaurus} eine umfassende Datenbank zur Verfügung, die Informationen über Worte, ihre Synonyme und noch weitere Eigenschaften enthält. Der Funktionsumfang enthält dabei den Export der kompletten Datenbank oder die Benutzung der internen API unter \textit{GNU Lesser General Public License (LGPL}.

\subsection{Rechtschreibprüfung und Metriken}
Da politische Texte vorwiegend von tatsächlichen Personen verfasst und nicht automatisiert erstellt werden, können sich in diese Texte natürlich Rechtschreibfehler einschleichen. Im Rahmen politischer Texte ist dies zwar unwahrscheinlich, da die Texte mehrfach von Experten Korrektur gelesen werden, jedoch nicht unmöglich. Werden hingegen Texte aus sozialen Medien oder ähnlichen Quellen analysiert, so steigt die Wahrscheinlichkeit, dass Wörter fehlerhaft geschrieben werden. Dabei können drei Fehler unterschieden werden:
\begin{itemize}
\item Hinzufügen eines Extrabuchstabens: Google - Gooogle
\item Entfernen eines relevanten Buchstabens: Google - Gogle
\item Austauschen eines Buchstabens: Google - Go0gle
\end{itemize}
Um beim Auftreten solcher Fehler dennoch ein korrektes Wort erkennen zu können werden sogenannte Metriken eingeführt. Diese beschreiben, ähnlich wie in der Mathematik, den Abstand zweier Zeichenketten. Dabei gilt:
\begin{itemize}
\item \( ||s1 - s2|| = 0 \) - der Abstand eines Wortes zu sich selbst ist Null
\item \( ||s1 - s2|| > 0, s1 \neq s2 \) - der Abstand zweier unterschiedlicher Worte ist größer Null
\item \( ||s1 - s2|| = ||s2 - s1|| \) - Kommutativität, die Wörter dürfen vertauscht werden
\item \( ||s1 - s3|| \leq ||s1 - s2|| + ||s2 - s3|| \) - Dreiecksungleichung, der kürzeste Abstand ist der direkte Weg
\end{itemize}
Die einfachste Metrik, welche die Bedingungen erfüllt, ist die \textit{Hamming Edit Distance}. Diese berechnet sich aus der Anzahl an Zeichen, die sich bei zwei Zeichenketten unterscheiden. Beide Zeichenketten haben normalerweise die gleiche Länge. Sollte sich diese jedoch unterscheiden, so wird der kürzere String mit Nullen am Ende erweitert.
\newline
Eine weitere Metrik ist die sogenannte \textit{Longest Common Subsequence (LCS)}. Diese gilt nur für Zeichenketten, in denen Zeichen hinzugefügt oder entfernt wurden. Wie der Name schon vermuten lässt, beschreibt die LCS die längste Folge von Zeichen, die in beiden Zeichenketten vorkommt.
\newline
Die \textit{Levenshtein Edit Distance} lässt sich aus der minimalen Anzahl an Operationen errechnen, die benötigt werden, um eine Zeichenkette in eine andere zu konvertieren. Gültige Operationen sind hierbei das Einfügen, Entfernen und Vertauschen von Zeichen.
\newline
\begin{table}
\center
\begin{tabular}{|l|ccc|}
\hline
Zeichenkette & Hamming & LCS & Levenshtein \\
\hline
Gooogle & 4 & 1 & 1 \\
Gogle & 4 & 1 & 1 \\
Go0gle & 1 & 1 & 1 \\
\hline
\end{tabular}
\caption{Rechtschreibfehler mit Distanz}
\end{table}
\newline
Wie man an den Beispielen sieht eignet sich der Hamming-Abstand nur bedingt für die Rechtschreibprüfung. Sein Vorteil ist jedoch die geringe Berechnungszeit gegenüber den beiden anderen Metriken. Insbesondere der Levenshtein-Abstand ist sehr berechnungsintensiv.
\newline
Die Anwendung im Programm könnte folgendermaßen aussehen: Sollte bei einem Wort aus gegebenem Grund angenommen werden, dass dieses falsch geschrieben wurde, so würde der Abstand zu allen weiteren verfügbaren Wörtern berechnet. Sollte dabei ein eindeutiges Minimum gefunden werden, so kann das Wort direkt verbessert werden. Bei multiplen Kandidaten kann eventuell mittels Heuristiken eine Verbesserung durchgeführt werden. Da alle möglichen Abstände berechnet werden müssen ist auch dieses Vorgehen sehr rechenintensiv.


\section{Comparative Manifesto Project}
Als Quellen für dieses Kapitel wurden \cite{csta} und \cite{cmp} verwendet.
Das Comparative Manifesto Project, kurz CMP, beschäftigt sich mit der Analyse politischer Texte und Standpunkte einer Vielzahl von Ländern und Parteien weltweit. Als Resultat stehen dem Nutzer der CMP Datenbank ausgiebige Informationen über die jeweiligen Texte zur Verfügung - und zwar in maschinell verwertbarer Form.
Das Auswerten der Texte erfolgt jedoch nicht durch ein Programm, sondern manuell durch eine effiziente Aufteilung auf verschiedene Arbeiter. Dieses Vorgehen wird Crowd-Sourcing genannt. Dabei werden die Texte in kompakte Pakete aufgeteilt und weltweit an verschiedene Arbeiter verteilt. Dieses Vorgehen hat einige Vorteile:
\begin{itemize}
\item Der Arbeiter hat nicht den ganzen Text zur Verfügung und muss daher den Teiltext objektiv und ohne Zusammenhang einordnen. Im Kontext des gesamten Textes könnten sonst subjektive Eindrücke das Ergebnis verfälsche.
\item Identische Teiltexte können an unterschiedliche Arbeiter verteilt werden. So lassen sich subjektive Einstellungen der Arbeiter herausfiltern. Für eine steigende Zahl an Arbeitern kann so ein möglichst objektives Ergebnis erzielt werden.
\end{itemize}
Als Ergebnis der Teilarbeit erhält man nun die Einordnung des Textes in ein Schema aus 56 Kategorien und Subkategorien. Diese Kategorien sollen das ganze politische Spektrum sinnvoll abbilden können. Die Hauptkategorien hierbei sind:
\begin{itemize}
\item External Relations
\item Freedom and Democracy
\item Political System
\item Economy
\item Welfare and Quality of Life
\item Fabric of Society
\item Social Groups
\end{itemize}
Diese lassen sich wiederum in Subkategorien einteilen um das Ergebnis detaillierter darstellen zu können. Da jede Aussage eines Textes solch einer Kategorie zugeordnet wird, erhält man so eine 56-dimensionale Darstellung des Textes, wobei jede Dimension eine politische Richtung darstellt.
Das Manifesto Project enthält seit 1945 ungefähr 4000 Texte von über 1000 Parteien aus mehr als 50 verschiedenen Ländern.
Die Daten können manuell über eine minimalistische Oberfläche abgefragt werden. Alternativ steht, nach einer initialen Registrierung, auch eine API zur automatischen Abfrage zur Verfügung.

\section{Repräsentative Demokratie in Deutschland}
Die Informationen über dieses Kapitel stammen aus \cite{bundestag}, \cite{bundesregierung} und \cite{wikipedia}.
\begin{quote}
"Die repräsentative Demokratie bezeichnet eine demokratische Herrschaftsform, bei der politische Entscheidungen und die Kontrolle der Regierung nicht unmittelbar vom Volk, sondern von einer Volksvertretung, zum Beispiel dem Parlament, ausgeübt werden.
Bürgerinnen und Bürger treffen politische Entscheidungen nicht selbst, sondern überlassen sie auf Zeit gewählten Vertretern, die für sie als Stellvertreter tätig sind. Die Bürger beteiligen sich aber an Wahlen und wirken in Parteien, Verbänden und Initiativen mit."
\end{quote}
\cite{bundestag}
Die Bundesregierung in Deutschland setzt sich aus aus der Bundeskanzlerin und den verschiedenen Bundesministerien zusammen. Aktuell besteht die Regierung aus einer Koalition von CDU/CSU und SPD. Eine kurze Übersicht bietet folgende Tabelle: \\
\begin{table}
\begin{tabular}{lll}
\hline
Name & Partei & Rolle \\
\hline
Angela Merkel & CDU & Bundeskanzlerin der Bundesrepublik Deutschland \\
Sigmar Gabriel & SPD & Bundesminister des Auswärtigen \\
Brigitte Zypries & SPD & Bundesministerin für Wirtschaft und Energie \\
Thomas de Maizière & CDU & Bundesminister des Innern \\
Heiko Maas & SPD & Bundesminister der Justiz und für Verbraucherschutz \\
Wolfgang Schäuble & CDU & Bundesminister der Finanzen \\
Andrea Nahles & SPD & Bundesministerin für Arbeit und Soziales \\
Christian Schmidt & CSU & Bundesminister für Ernährung und Landwirtschaft \\
Ursula von der Leyen & CDU & Bundesministerin der Verteidigung \\
Katarina Barley  & SPD & Bundesministerin für Familie, Senioren, Frauen und Jugend \\
Hermann Gröhe & CDU & Bundesminister für Gesundheit \\
Alexander Dobrindt & CSU & Bundesminister für Verkehr und digitale Infrastruktur \\
Barbara Hendricks & SPD & Bundesministerin für Umwelt, Naturschutz, Bau und  \\
& & Reaktorsicherheit \\
Johanna Wanka & CDU & Bundesministerin für Bildung und Forschung \\
Gerd Müller & CSU & Bundesminister für wirtschaftliche Zusammenarbeit und \\
& & Entwicklung \\
Peter Altmaier & CDU & Chef des Bundeskanzleramtes und Bundesminister für  \\
& & besondere Aufgaben \\
\hline
\end{tabular}
\caption{Übersicht Bundesregierung}
\end{table}
Im Gegensatz dazu sind im Bundestag alle gewählten Parteien vertreten, die über die "Fünf Prozent Hürde" gekommen sind. Dazu gehören, abgesehen von CDU/CSU und SPD, Die Linke und BÜNDNIS 90/DIE GRÜNEN. Weitere wichtige Parteien im politischen Spektrum sind die FDP und die AfD. Wichtige Personen in diesem Zusammenhang sind die Parteivorsitzenden und deren Stellvertreter: \\
\begin{table}
\begin{tabular}{lll}
\hline
Partei & Parteivorsitzender & stellvertretende Vorsitzende \\
\hline
& & Volker Bouffier \\
& & Ursula von der Leyen \\
CDU & Angela Merkel & Julia Klöckner \\
& & Armin Laschet\\
& & Thomas Strobl \\
\hline
& & Manfred Weber \\
& & Christian Schmidt \\
CSU & Horst Seehofer &  Barbara Stamm \\
& & Angelika Niebler\\
& & Kurt Gribl \\
\hline
& & Thorsten Schäfer-Gümbel \\
& & Manuela Schwesig \\
SPD & Martin Schulz & Olaf Scholz\\
& & Aydan Özoğuz\\
& & Ralf Stegner \\
\hline
Bündnis 90/Die Grünen & Cem Özdemir \\
& Simone Peter & \\
\hline
& & Caren Lay \\
Die Linke & Katja Kipping & Axel Troost\\
& Bernd Riexinger & Tobias Pflüger \\
& & Janine Wissler \\
\hline
& & Wolfgang Kubicki \\
FDP & Christian Lindner & Marie-Agnes Strack-Zimmermann\\
& & Katja Suding \\
\hline
& Frauke Petry & Alexander Gauland \\
AfD & Jörg Meuthen & Beatrix von Storch \\
& & Albrecht Glaser \\
\hline
\end{tabular}
\caption{Große Deutsche Parteien mit Vorsitzenden}
\end{table}
Abgesehen von den oben genannten Politikern gibt es noch weitere Ämter, wie beispielsweise Fraktionsvorsitzende oder Generalsekretäre, welche ebenfalls eine wichtige Informationsquelle darstellen, hier aber nicht explizit aufgeführt werden. Bis auf wenige Ausnahmen sind alle oben genannten Politiker in den sozialen Medien aktiv und es ist somit möglich, poltische Texte abzufragen. Da diese durch die professionellen Büros der Politiker erstellt werden, sind sie in angebrachter Sprache und Grammatik verfasst. Somit sind sie auch für die Analyse mit Hilfe des Modells verwendbar, da sich der Wortschatz ähneln sollte.
